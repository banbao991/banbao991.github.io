<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.jpg">
  <link rel="mask-icon" href="/images/apple-touch-icon-next.jpg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha256-AbA177XfpSnFEvgpYu1jMygiLabzPCJCRIBtR5jGc0k=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.13.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="提出了 N-BVH，在 BVH 架构的基础上，在光线与场景求交的时候，一些子树内部节点的查询使用神经网络查询替代，从而实现场景属性的压缩，目前场景中能够学习的属性是交点、albedo、normal（其他的参数还是写死的）。速度上比 PT 慢一些，但是压缩效果很好。">
<meta property="og:type" content="article">
<meta property="og:title" content="(论文)[2024-SIG-C] N-BVH: Neural ray queries with bounding volume hierarchies">
<meta property="og:url" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/index.html">
<meta property="og:site_name" content="Banbao">
<meta property="og:description" content="提出了 N-BVH，在 BVH 架构的基础上，在光线与场景求交的时候，一些子树内部节点的查询使用神经网络查询替代，从而实现场景属性的压缩，目前场景中能够学习的属性是交点、albedo、normal（其他的参数还是写死的）。速度上比 PT 慢一些，但是压缩效果很好。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/poor-correlation.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/encoding-network.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/fig4-sampling-points.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/fig5-shallow-vs-1-node.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/fig2-N-BVH.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/sup-alg1.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/fig-4-for-distance.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/error.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/scene-params.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/table1-chess.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/fig6-chess1.png">
<meta property="og:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/fig7-compression-rate.png">
<meta property="article:published_time" content="2024-05-27T04:26:09.000Z">
<meta property="article:modified_time" content="2024-08-05T11:57:05.721Z">
<meta property="article:author" content="banbao(990)">
<meta property="article:tag" content="CG">
<meta property="article:tag" content="NN">
<meta property="article:tag" content="Paper">
<meta property="article:tag" content="SIG">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/poor-correlation.png">


<link rel="canonical" href="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2024/05/27/CG/Papers/2024/N-BVH/","path":"2024/05/27/CG/Papers/2024/N-BVH/","title":"(论文)[2024-SIG-C] N-BVH: Neural ray queries with bounding volume hierarchies"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>(论文)[2024-SIG-C] N-BVH: Neural ray queries with bounding volume hierarchies | Banbao</title>
  






  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Banbao</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-categories(2)"><a href="/kits/paper-lists/" rel="section"><i class="fa fa-print fa-fw"></i>Categories(2)</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-more-notes"><a href="https://github.com/banbao990/Use/" rel="noopener" target="_blank"><i class="fa fa-book fa-fw"></i>More notes</a></li><li class="menu-item menu-item-use"><a href="/use/" rel="section"><i class="fa fa-gamepad fa-fw"></i>Use</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#tldr"><span class="nav-text">TLDR</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#n-bvh"><span class="nav-text">N-BVH</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction"><span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B4%A1%E7%8C%AE"><span class="nav-text">贡献</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="nav-text">应用场景</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#related-work"><span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#method-overview"><span class="nav-text">Method Overview</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#neural-ray-query"><span class="nav-text">Neural Ray Query</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#motivation"><span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#network"><span class="nav-text">Network</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sampling"><span class="nav-text">Sampling</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#neural-bvh"><span class="nav-text">Neural BVH</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#error-driven-construction"><span class="nav-text">Error-driven construction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#base-bvh-cut-optimization"><span class="nav-text">Base-BVH cut optimization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#node-error"><span class="nav-text">Node error</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#node-training-and-losses"><span class="nav-text">Node training and losses</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#ray-distribution"><span class="nav-text">Ray distribution</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#loss"><span class="nav-text">Loss</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#level-of-detail"><span class="nav-text">Level of detail</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0"><span class="nav-text">实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80"><span class="nav-text">基础</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%86%E8%8A%82"><span class="nav-text">细节</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BA%94%E7%94%A8"><span class="nav-text">应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hybrid-path-tracing"><span class="nav-text">Hybrid Path Tracing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C"><span class="nav-text">结果</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="nav-text">消融实验</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#neural-prefiltering"><span class="nav-text">Neural Prefiltering</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%A8%E8%AE%BA"><span class="nav-text">讨论</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#limitations"><span class="nav-text">Limitations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#future-work"><span class="nav-text">Future Work</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="banbao(990)"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">banbao(990)</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">340</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">108</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/banbao990" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;banbao990" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2369896555@qq.com" title="E-Mail → mailto:2369896555@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/banbao990" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/05/27/CG/Papers/2024/N-BVH/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="banbao(990)">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Banbao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="(论文)[2024-SIG-C] N-BVH: Neural ray queries with bounding volume hierarchies | Banbao">
      <meta itemprop="description" content="提出了 N-BVH，在 BVH 架构的基础上，在光线与场景求交的时候，一些子树内部节点的查询使用神经网络查询替代，从而实现场景属性的压缩，目前场景中能够学习的属性是交点、albedo、normal（其他的参数还是写死的）。速度上比 PT 慢一些，但是压缩效果很好。">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          (论文)[2024-SIG-C] N-BVH: Neural ray queries with bounding volume hierarchies
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-05-27 12:26:09" itemprop="dateCreated datePublished" datetime="2024-05-27T12:26:09+08:00">2024-05-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-08-05 19:57:05" itemprop="dateModified" datetime="2024-08-05T19:57:05+08:00">2024-08-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/CG-Paper/" itemprop="url" rel="index"><span itemprop="name">CG.Paper</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

            <div class="post-description">提出了 N-BVH，在 BVH 架构的基础上，在光线与场景求交的时候，一些子树内部节点的查询使用神经网络查询替代，从而实现场景属性的压缩，目前场景中能够学习的属性是交点、albedo、normal（其他的参数还是写死的）。速度上比 PT 慢一些，但是压缩效果很好。</div>
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="tldr">TLDR</h1>
<ul>
<li>任务：<strong>光追背景</strong>，输入光线，输出交点、albedo、normal
<ul>
<li>生成反射光线：交点+normal（+场景中写死的BSDF参数）</li>
</ul></li>
<li>创新点：压缩场景（速度差不多、结果可接受的情况下，显存变为10%）</li>
</ul>
<h1 id="n-bvh">N-BVH</h1>
<ul>
<li>N-BVH: Neural ray queries with bounding volume hierarchies</li>
<li>Philippe Weier，DFKI，Saarland University</li>
<li>论文：<a target="_blank" rel="noopener" href="https://weiphil.github.io/portfolio/neural_bvh">作者网站</a></li>
<li>代码：<a target="_blank" rel="noopener" href="https://github.com/WeiPhil/nbvh">Github</a></li>
</ul>
<h2 id="摘要">摘要</h2>
<ul>
<li>神经网络在压缩信号方面很有效
<ul>
<li>渲染中，大量存储被用于纹理和几何</li>
<li>压缩！</li>
</ul></li>
<li>挑战：训练时间短、推理时间快的 trade off</li>
<li>multi-resolution hash grid
<ul>
<li>使用 adaptive BVH-driven probing scheme 优化参数</li>
</ul></li>
<li>可以将 non-neural 和 neural 的方法结合，取各自的长处</li>
<li>论文：Neural BVH or N-BVH（<span class="math inline">\(\mathcal{N}\text{-BVH}\)</span>）</li>
<li>可以实现
<ul>
<li>accurate <strong>ray queries</strong></li>
<li>faithful approximations of <strong>visibility, depth, and appearance
attributes</strong></li>
</ul></li>
</ul>
<h2 id="introduction">Introduction</h2>
<ul>
<li>BVH：加速光线与场景求交
<ul>
<li>问题：内存（显存）占用过大</li>
</ul></li>
<li>Our <strong>key observation</strong> is that any neural compression
model can be optimized efficiently as long as it is trained on samples
that live close to the signal of interest.
<ul>
<li>神经网络总是能过拟合</li>
</ul></li>
<li>训练：使用场景的 BVH 生成 ray queries/responses 数据对
<ul>
<li>几分钟</li>
</ul></li>
<li>推理：和 BVH 类似，但是不需要 full, deep BVH traversal and hence
storage</li>
<li>N-BVH 可以和 standard BVH 一起使用</li>
<li>N-BVH 还有一套 simple level-of-detail (LoD) scheme</li>
<li>hash grid 的好处：稀疏编码
<ul>
<li>faster and easier training</li>
</ul></li>
</ul>
<h3 id="贡献">贡献</h3>
<ul>
<li>N-BVH 的数据结构</li>
<li>neural ray-intersection query mechanism</li>
<li>fast training scheme driven by a coarse-to-fine tree-cut
optimization
<ul>
<li>哪里误差大优化哪里</li>
</ul></li>
<li>multiple adaptive neural levels of-detail</li>
</ul>
<h3 id="应用场景">应用场景</h3>
<ul>
<li>hybrid path tracing</li>
<li>neural appearance prefiltering</li>
</ul>
<h2 id="related-work">Related Work</h2>
<ul>
<li>Neural implicit representations（神经隐式表示）
<ul>
<li>NeRF</li>
<li>novel view synthesis</li>
<li>位置编码：<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3528223.3530127">稀疏编码</a>、<a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3528233.3530727">压缩编码</a></li>
<li>NeRF 相关
<ul>
<li><a target="_blank" rel="noopener" href="https://phog.github.io/snerg/">accumulating features along
rays</a> 从而减少 dense MLP queries 的负担</li>
<li><a target="_blank" rel="noopener" href="https://github.com/RichealYoung/TINC">tree-structured
MLP</a>（improve compression fidelity）</li>
<li>further speed and accuracy can be gained with an <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3618390">adequate empty-space
skipping strategy</a>
<ul>
<li>减少 MLP 查询、提高信号质量（采样的都是表面附近的）</li>
</ul></li>
</ul></li>
</ul></li>
<li>Geometric simplification（几何简化）
<ul>
<li>Silhouette and shape-preserving decimation（<strong>often with
artist supervision</strong>）</li>
<li>...</li>
</ul></li>
<li>Neural compressed geometric reconstruction（神经压缩的几何重建）
<ul>
<li>使用 SDF 替代 Mesh 表示
<ul>
<li>提出（慢、低频）</li>
<li>octree feature volume：高频</li>
<li>optimized space partitioning：高压缩率、准确</li>
</ul></li>
<li>直接再三角形上做
<ul>
<li><a target="_blank" rel="noopener" href="https://doi.org/10.1145/3592443">a sparse voxel grid paired
with a hash grid</a></li>
</ul></li>
<li><a target="_blank" rel="noopener" href="https://augmentariumlab.github.io/PRIF/">learning
visibility and depth for arbitrary ray queries</a>
<ul>
<li><span style="color:red">ray-foot parameterization</span>
避免相同交点的混淆（<span class="math inline">\((p,d),(p+\delta
d,d)\)</span> 结果应该相同，但是简单的编码，网络很难输出相同结果）</li>
<li>没有对几何做压缩，因此需要很大的 MLP 进行推理</li>
<li><span style="color:red">
visibility</span>：这里的可见性指的是，只学到了最外层的点吧</li>
</ul></li>
<li>Neural VDB</li>
</ul></li>
<li>Hybrid neural path tracing
<ul>
<li><span style="color:red">shadow ray 可见性问题</span>：<a target="_blank" rel="noopener" href="https://doi.org/10.2312/hpg.20231135">Neural Intersection
Function</a>（AMD）</li>
<li>过拟合光源和相机位置，交互性差、不能 relighting</li>
</ul></li>
</ul>
<h2 id="method-overview">Method Overview</h2>
<ul>
<li>使用神经网络<strong>替代</strong> BVH Mesh
<ul>
<li>infer intersection point, surface normal, and appearance.</li>
</ul></li>
<li>基于 multi resolution hash grid</li>
<li>Neural ray inference
<ul>
<li>存在误差</li>
<li>网络大小、<strong>输入编码</strong>都会影响网络性能
<ul>
<li>让样本都在表面附近 <span class="math inline">\(\to\)</span>
高效</li>
<li>密集采样太慢了，传统 BVH 做指导（在相交的 BVH 中进行采样）</li>
</ul></li>
</ul></li>
<li>a single global neural model 编码整个场景几何</li>
<li>最终：no geometrical primitives, no textures, and only a shallow BVH
<ul>
<li><strong>压缩率高</strong></li>
</ul></li>
</ul>
<h2 id="neural-ray-query">Neural Ray Query</h2>
<ul>
<li>训练：几何元素+包围盒 <span class="math inline">\(\to\)</span>
交点信息</li>
</ul>
<h3 id="motivation">Motivation</h3>
<ul>
<li>query 最简单的参数化：ray-box entry and exit points
<ul>
<li>效果差
<ul>
<li>这种编码和要学习的信号（交点）相关性差</li>
<li>导致 blur、loss in accuracy</li>
</ul></li>
<li>下图以 entry point 为例
<ul>
<li>相同的入射点，交点相差很大（网络学习到平均信息）</li>
<li>如果 encoding point <strong>更加接近表面</strong>，那么差距越小</li>
<li>最理想的话直接就是交点</li>
</ul></li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/poor-correlation.png"></p>
<h3 id="network">Network</h3>
<ul>
<li>Encoding, inference &amp; training</li>
<li>我们不知道交点（正是我们想计算的）</li>
<li>输入
<ul>
<li>采样若干个点形成 ray-box intersection interval</li>
<li>保存到 multi-resolution grid 里面（经过 grid 之后，position 变成
feature）</li>
<li>concatenate（有序的，编码了方向）</li>
<li>过小 MLP</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/encoding-network.png"></p>
<ul>
<li>pipeline
<ul>
<li>采样光线
<ul>
<li>均匀的场景中采样起点，50%-inflated scene bounding box（50%
膨胀的场景 AABB 包围盒）</li>
<li>均匀采样一个方向</li>
</ul></li>
<li>输入模型
<ul>
<li>真实值（GT）为光线与场景求交的实际结果</li>
</ul></li>
</ul></li>
<li>loss：根据具体信号具体设计</li>
<li>优化：梯度下降</li>
</ul>
<h3 id="sampling">Sampling</h3>
<ul>
<li>Sampling &amp; reconstruction quality.</li>
<li>光线的编码：光线上的若干个点</li>
<li>采样点
<ul>
<li>例如：光线上采样 2 个点，则采样点位置为 25%，75%
<ul>
<li><span class="math inline">\(x\to\dfrac{2i+1}{2x}\)</span>，<span class="math inline">\(i=0,\cdots,x-1\)</span></li>
</ul></li>
</ul></li>
<li>当有一个样本点在物体表面（第一个交点）的时候，效果好
<ul>
<li>例子：45度倾斜的棋盘格</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/fig4-sampling-points.png"></p>
<ul>
<li>期望靠近表面
<ul>
<li>naive：增加采样个数，<strong>开销增大</strong></li>
<li>N-BVH 解决了这个问题（使用 BVH 做引导）</li>
</ul></li>
</ul>
<h2 id="neural-bvh">Neural BVH</h2>
<ul>
<li>期望光线上的采样点靠近物体表面</li>
<li>使用场景 BVH 作为引导，只需要考虑相交的 ray segment
<ul>
<li>We split the input geometry into smaller, simpler pieces, enclosing
each in a tight bounding box.（似乎作者的 <strong>BVH/三角网格</strong>
特别精细？）</li>
<li>实现了我们的目标
<ul>
<li>front-to back ray traversal</li>
<li>empty-space skipping</li>
<li>probing the model closer to the geometry</li>
</ul></li>
</ul></li>
<li>一条光线总的查询次数（neural queries）：在找到交点之前碰到的 BVH
叶子节点个数</li>
<li>一个浅层的 N-BVH 比使用单个 neural node 效果好很多，如<span id="fig5">下图</span>
<ul>
<li>第一排：每一个节点的平均 <span id="error-vis">training loss</span>
可视化</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/fig5-shallow-vs-1-node.png"></p>
<ul>
<li><span id="n-bvh-structure">N-BVH 的结构</span>
<ul>
<li>和传统的 BVH 相比，节点数量更少（少1-2个数量级）</li>
<li>Nerual Node 是空心（hollow）的，具体内容是保存在1个大的网络中</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/fig2-N-BVH.png"></p>
<h3 id="error-driven-construction">Error-driven construction</h3>
<ul>
<li>想要让场景的 inference error 差不多（叶子结点的 error
相同），见上面的<a href="#error-vis">可视化</a></li>
<li>top-down approach
<ul>
<li>switch between <strong>model training</strong> &amp; <strong>node
splitting</strong></li>
</ul></li>
</ul>
<h4 id="base-bvh-cut-optimization">Base-BVH cut optimization</h4>
<ul>
<li>直接使用场景 input-geometry 的 BVH（base BVH）</li>
<li><strong>迭代法</strong>找到 Tree-cut（含义见<a href="#n-bvh-structure">图</a>）</li>
<li>每轮迭代：将 cut 移动的更深，<strong>cut 相邻的浅层节点作为 Neural
Node</strong>
<ul>
<li>先<a href="#node-training-and-losses">训练网络</a></li>
<li>找到最大 error 的结点，使用他们的子节点替代（将子节点作为 Neural
Node）
<ul>
<li>分裂几个节点（top-k），由用户指定</li>
</ul></li>
</ul></li>
<li>迭代次数
<ul>
<li>用户指定 Neural Node 的个数，当达到用户指定值的时候，停止迭代</li>
<li>随着迭代次数增加，cut 变大，Neural Node 增多</li>
</ul></li>
<li>详细算法
<ul>
<li>frequency <span class="math inline">\(f\)</span>：迭代多少次分裂
nodes（更新 tree cut）</li>
<li>scaling factor <span class="math inline">\(s_n&gt;1\)</span>：每次分裂数目不一样，越来越多</li>
<li>scaling factor <span class="math inline">\(s_t&gt;1\)</span>：间隔时间越来越长（tree-cut
变大了，需要更多样本训练）</li>
</ul></li>
<li>参数：<span class="math inline">\(t=3000,s_t=2\)</span></li>
</ul>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">Target node count</th>
<th style="text-align: center;"><span class="math inline">\(f\)</span></th>
<th style="text-align: center;"><span class="math inline">\(s_n\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">3000</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr class="even">
<td style="text-align: center;">155</td>
<td style="text-align: center;">300</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.2k</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr class="even">
<td style="text-align: center;">11k</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">2.3</td>
</tr>
<tr class="odd">
<td style="text-align: center;">33k</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">2.5</td>
</tr>
<tr class="even">
<td style="text-align: center;">73k</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">3.2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">142k</td>
<td style="text-align: center;">90</td>
<td style="text-align: center;">5.0</td>
</tr>
</tbody>
</table>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/sup-alg1.png"></p>
<h4 id="node-error">Node error</h4>
<ul>
<li><p>Neural Node 的 error 如何评估？</p></li>
<li><p><span class="math inline">\(q\cdot p\)</span>：具体的见下一个 <a href="#node-training-and-losses">section</a></p>
<ul>
<li><span class="math inline">\(q\)</span>：node 的 training loss</li>
<li><span class="math inline">\(p\)</span>：random ray hit it 的概率
<ul>
<li>正比于 node 的表面积（因为训练的时候光线是均匀分布在场景中的）</li>
<li>实际实现的时候，我们使用击中当前 node 的光线比例进行估计</li>
</ul></li>
</ul></li>
<li><p>使用 <span class="math inline">\(r\)</span> 替代</p>
<ul>
<li><span class="math inline">\(r=2\log q+\log
p=\log(q^2p)\)</span></li>
<li>直接使用 top-k 的 <span class="math inline">\(p\cdot q\)</span>
会导致对于 large and/or high-loss nodes 的过度激进分裂</li>
<li><span class="math inline">\(\log\)</span>：减小激进程度（log-scale）</li>
<li><span class="math inline">\(2\)</span>​：减小对于 large, low-loss
nodes 的分裂次数（减轻 node 大小的影响）</li>
</ul></li>
<li><p><a href="#fig5">上图</a>使用的就是 <span class="math inline">\(r\)</span></p></li>
<li><p>补充材料中给出了一个复杂 mesh，对比 <span class="math inline">\(r\text{-optimization}\)</span>​ 和 fixed-depth,
uniform node splitting 相比的结果</p>
<ul>
<li><span class="math inline">\(r\)</span> 好</li>
<li><span style="color:red">为什么不对比 <span class="math inline">\(r\)</span> 和 <span class="math inline">\(p\cdot
q\)</span></span></li>
</ul></li>
</ul>
<h3 id="node-training-and-losses">Node training and losses</h3>
<ul>
<li>只训练 Neural Node 中的部分</li>
<li>这个部分：训练 high-error 的 Node、loss</li>
</ul>
<h4 id="ray-distribution">Ray distribution</h4>
<ul>
<li>让 loss 分布更均匀 &amp; 使训练更有效（limited budget）</li>
<li>策略 1
<ul>
<li>每条光线只关注第一个相交的 node</li>
<li>focuses the effort on more <strong>visible</strong> nodes</li>
</ul></li>
<li>策略 2：loss 小训练概率小
<ul>
<li>相交的 node 以 <span class="math inline">\(\max(r/r_{\max},0.005)\)</span> 的概率训练</li>
<li><span class="math inline">\(r_{\max}\)</span>：largest error in the
cut（Neural Nodes）</li>
</ul></li>
</ul>
<h4 id="loss">Loss</h4>
<ul>
<li>Visibility
<ul>
<li>在相交 ray
segment（entry-exit）上的可见性问题可以被定义为一个二分问题</li>
<li>sigmoid activation</li>
<li>binary cross-entropy loss（比 L2 好）</li>
<li>最容易学习的，用于指导其他的 loss 部分
<ul>
<li>如果 gt-visibility 为 1（没有交点），那么其他的 loss 都设置为 0</li>
<li>不需要学习（用不到）</li>
</ul></li>
</ul></li>
<li>Intersection point
<ul>
<li>备选：下图是结果的可视化，应该和上面的<a href="#fig5">这个图</a>一样
<ul>
<li>1D（到光线起点的 distance），3D（位置）</li>
<li>locally（相对于 node 本身）、globally</li>
</ul></li>
<li>尝试后，发现 locally+1D 效果好
<ul>
<li>L1 Loss</li>
</ul></li>
<li>解释：1D 的信号更好学习</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/fig-4-for-distance.png"></p>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/error.png"></p>
<ul>
<li>Auxiliary intersection data
<ul>
<li>只有 normal+albedo
<ul>
<li><strong>the other BSDF parameters are fixed by the user</strong>
<ul>
<li>也就是说其他 BSDF 参数不能从网络中获取</li>
</ul></li>
</ul></li>
<li>实验发现
<ul>
<li>albedo：relative L2 loss</li>
<li>normal：L1 loss</li>
</ul></li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/scene-params.png"></p>
<ul>
<li>2：实验发现重视 visibility 和 distance 更好</li>
</ul>
<p><span class="math display">\[
L =
2L_{\text{visibility}}+2L_{\text{distance}}+L_{\text{normal}}+L_{\text{albedo}}
\]</span></p>
<h3 id="level-of-detail">Level of detail</h3>
<ul>
<li>设置 multiple base-BVH cuts，每一个对应 LoD 的一个层级</li>
<li>register a new LoD at regular training iteration intervals.</li>
<li>随机选择一个 tree-cut（对应一个 LoD）进行训练</li>
</ul>
<h2 id="实现">实现</h2>
<h3 id="基础">基础</h3>
<ul>
<li>fully software-based <strong>CUDA wavefront path
tracer</strong></li>
<li>tiny-cuda-nn
<ul>
<li>half-precision scalars</li>
</ul></li>
<li>neural prefiltering 在 RTX 3080，其他都是 RTX 3090</li>
</ul>
<h3 id="细节">细节</h3>
<ul>
<li>BVH construction
<ul>
<li>N-BVH 需要自己操纵，因此不能利用硬件加速</li>
<li>CPU 建立，传到 GPU
<ul>
<li><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/1572769.1572771">sweeping
SAH builder</a></li>
</ul></li>
</ul></li>
<li>网络
<ul>
<li>batches size：<span class="math inline">\(2^{18}\)</span></li>
<li>Adam optimizer
<ul>
<li>lr：0.01</li>
</ul></li>
<li>MLP
<ul>
<li>4 hidden layers，64 neurons each</li>
<li>ReLU</li>
</ul></li>
<li>网络输出
<ul>
<li>normal：linear activation</li>
<li>其他：sigmoid activation</li>
</ul></li>
<li>hash grid
<ul>
<li>8 levels：<span class="math inline">\(8^3\to1024^3\)</span></li>
<li>4 features per level</li>
</ul></li>
<li>只通过修改 hash-map size 来调整网络大小</li>
</ul></li>
<li>BVH 边界很小的时候，可能受到浮点数误差的影响
<ul>
<li><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3592443">之前工作</a>可以减轻这个问题</li>
</ul></li>
</ul>
<h2 id="应用">应用</h2>
<h3 id="hybrid-path-tracing">Hybrid Path Tracing</h3>
<ul>
<li>主要是起到压缩场景、减小显存开销的作用</li>
<li>TLAS + BLAS
<ul>
<li>each BLAS is either a classical BVH or our N-BVH</li>
<li>一般来说，一个 mesh 一个 BLAS</li>
</ul></li>
</ul>
<h4 id="结果">结果</h4>
<ul>
<li>一个示例：1920×1080
<ul>
<li>只压缩复杂的东西（棋子），棋盘格没有压缩</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/table1-chess.png"></p>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/fig6-chess1.png"></p>
<ul>
<li>Reconstruction quality &amp; performance
<ul>
<li>trade off
<ul>
<li>render times &amp; reconstruction quality</li>
</ul></li>
<li>主要和 Neural Nodes 的数量相关，和 Hash Grid Size 相关性小一些</li>
</ul></li>
<li>Compression rate
<ul>
<li>通过调整 Hash Grid Size 来调整压缩率</li>
<li>Neural Node 数：33k</li>
<li>因为有些东西不压缩，这里给了两个指标</li>
<li>最主要的压缩来源是 mesh 的简化</li>
<li>还放了一个 3D 扫描的 2.69G 的猛犸象</li>
</ul></li>
</ul>
<p><img src="/2024/05/27/CG/Papers/2024/N-BVH/fig7-compression-rate.png"></p>
<h4 id="消融实验">消融实验</h4>
<ul>
<li>Hash-grid size vs. node count
<ul>
<li>error 的主要影响因素：Neural Node 的数量</li>
<li>memory footprint 的主要影响因素：hash grid size（可学习参数多）</li>
</ul></li>
<li>Training time
<ul>
<li>最影响训练时间（error）的也是 Neural Node 的数量
<ul>
<li>多了，traversal 的时间长了</li>
</ul></li>
</ul></li>
<li>Hash-grid utilization
<ul>
<li>mesh 分布稀疏的时候，hash grid 的优势体现出来了</li>
</ul></li>
</ul>
<h3 id="neural-prefiltering">Neural Prefiltering</h3>
<ul>
<li>neural prefiltering 可以在感知 error 较低的情况下节省大量存储
<ul>
<li><a target="_blank" rel="noopener" href="https://doi.org/10.1145/3592443">Neural Prefiltering for
Correlation-Aware Levels of Detail</a></li>
</ul></li>
<li><span style="color:red">这个暂时还没看，等到看完上面这个论文再说</span></li>
</ul>
<h2 id="讨论">讨论</h2>
<h3 id="limitations">Limitations</h3>
<ul>
<li>assumption of convexity (or concavity) of the geometry inside a
neural node
<ul>
<li>当 Neural Node 比较少的时候，存在误差</li>
</ul></li>
<li>局限：the fixed number of encoded points per node
<ul>
<li>适应性的分布 points 个数效果会更好</li>
</ul></li>
</ul>
<h3 id="future-work">Future Work</h3>
<ul>
<li>泛化
<ul>
<li>mesh 表示到任意可以求交点的表示</li>
<li>dynamic geometry</li>
</ul></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CG/" rel="tag"># CG</a>
              <a href="/tags/NN/" rel="tag"># NN</a>
              <a href="/tags/Paper/" rel="tag"># Paper</a>
              <a href="/tags/SIG/" rel="tag"># SIG</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/05/09/CG/mitsuba3/02/" rel="prev" title="[M3] 学习日志">
                  <i class="fa fa-chevron-left"></i> [M3] 学习日志
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2024/05/31/CG/Papers/2022/PRIF/" rel="next" title="(论文)[2022-ECCV] PRIF: Primary Ray-based Implicit Function">
                  (论文)[2022-ECCV] PRIF: Primary Ray-based Implicit Function <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2021 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">banbao(990)</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>


  
    <script src='https://unpkg.com/mermaid/dist/mermaid.min.js'></script>
  
    <script>
      if (window.mermaid) {
        mermaid.initialize({theme: 'forest'});
      }
    </script>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js" integrity="sha256-o88AwQnZB+VDvE9tvIXrMQaPlFFSUTR+nldQm1LuPXQ=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.1.7/mermaid.min.js","integrity":"sha256-G58AID1YoX5YaEtWfXSI0VLrZ6N4kvNvwg0BI8zUFxE="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>

  <script src="/js/third-party/fancybox.js"></script>


  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
